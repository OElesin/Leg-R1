{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Hyperscaler Training for Legal Reasoning Model (Part 3)\n",
    "\n",
    "This notebook demonstrates how to train the Legal Reasoning Model using SageMaker Hyperscaler on ml.g5.8xlarge instances for optimal price-performance.\n",
    "\n",
    "## Part 3: Training Job Configuration and Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, let's import the necessary libraries and load the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import datetime\n",
    "\n",
    "# Load configuration\n",
    "config_path = \"../configs/hyperscaler_config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set AWS region\n",
    "region = 'us-east-1'  # Change to your preferred region\n",
    "\n",
    "# Create SageMaker session\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'legal-reasoning-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SageMaker Estimator\n",
    "\n",
    "Create a SageMaker HuggingFace estimator with Hyperscaler configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load distribution and hyperparameters from previous notebook\n",
    "# In a real notebook, you would define these here or load from a file\n",
    "\n",
    "# For brevity, we'll assume distribution and hyperparameters are defined\n",
    "# Please run Part 2 notebook first to define these variables\n",
    "\n",
    "# Set up training job name\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "job_name = f\"legal-reasoning-{config['model']['language']}-{timestamp}\"\n",
    "\n",
    "# Set up instance configuration\n",
    "instance_type = config['aws']['instance_type']\n",
    "instance_count = config['aws']['instance_count']\n",
    "use_spot = config['aws']['use_spot']\n",
    "max_wait = config['aws']['max_wait'] if use_spot else None\n",
    "max_run = config['aws']['max_run']\n",
    "\n",
    "# Set up output path\n",
    "output_path = f\"s3://{bucket}/{prefix}/model\"\n",
    "checkpoint_s3_uri = f\"s3://{bucket}/{prefix}/checkpoints\" if use_spot else None\n",
    "\n",
    "print(f\"Job Name: {job_name}\")\n",
    "print(f\"Instance Type: {instance_type}\")\n",
    "print(f\"Using Spot Instances: {use_spot}\")\n",
    "print(f\"Output Path: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HuggingFace estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"train_hyperscaler.py\",  # Custom training script with model parallelism\n",
    "    source_dir=\"../src/training\",         # Directory containing the training code\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    role=role,\n",
    "    transformers_version=\"4.28.1\",\n",
    "    pytorch_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "    use_spot_instances=use_spot,\n",
    "    max_wait=max_wait,\n",
    "    max_run=max_run,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    output_path=output_path,\n",
    "    base_job_name=job_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training Job\n",
    "\n",
    "Define data channels and start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data channels\n",
    "data_channels = {\n",
    "    \"train\": f\"s3://{bucket}/{prefix}/data/train\",\n",
    "    \"validation\": f\"s3://{bucket}/{prefix}/data/validation\"\n",
    "}\n",
    "\n",
    "print(\"Data Channels:\")\n",
    "print(json.dumps(data_channels, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training job\n",
    "# Note: This will actually start the training job on SageMaker\n",
    "# Uncomment the following line to run the training job\n",
    "\n",
    "# huggingface_estimator.fit(inputs=data_channels, job_name=job_name)\n",
    "\n",
    "print(\"To start the training job, uncomment the line above.\")\n",
    "print(\"Note: This will incur AWS charges for SageMaker training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Training Job\n",
    "\n",
    "Monitor the training job progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training job status\n",
    "# Note: This assumes you've started a training job\n",
    "\n",
    "# Replace with your actual job name if you started a training job\n",
    "example_job_name = job_name\n",
    "\n",
    "print(f\"To check the status of your training job, run:\")\n",
    "print(f\"aws sagemaker describe-training-job --training-job-name {example_job_name}\")\n",
    "\n",
    "print(\"\\nTo view the logs, run:\")\n",
    "print(f\"aws logs get-log-events --log-group-name /aws/sagemaker/TrainingJobs --log-stream-name {example_job_name}/algo-1-XXXXXXXXXX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Analysis\n",
    "\n",
    "Analyze the cost of the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate estimated cost\n",
    "estimated_hours = 25  # Estimated training time in hours\n",
    "on_demand_price = 5.76  # ml.g5.8xlarge on-demand price per hour\n",
    "spot_price = 1.73  # ml.g5.8xlarge spot price per hour (approximately 30% of on-demand)\n",
    "\n",
    "on_demand_cost = on_demand_price * estimated_hours\n",
    "spot_cost = spot_price * estimated_hours\n",
    "\n",
    "print(f\"Estimated training time: {estimated_hours} hours\")\n",
    "print(f\"On-demand cost: ${on_demand_cost:.2f}\")\n",
    "print(f\"Spot cost: ${spot_cost:.2f}\")\n",
    "print(f\"Cost savings with spot: ${on_demand_cost - spot_cost:.2f} ({(1 - spot_cost/on_demand_cost)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
